{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULhLIHXQ9v0l"
      },
      "source": [
        "# IMPORTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HnEBshM95vIj"
      },
      "outputs": [],
      "source": [
        "!pip install pydicom\n",
        "!pip install nibabel\n",
        "\n",
        "from torch import nn\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from ipywidgets import interact, IntSlider\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import pydicom\n",
        "import nibabel as nib\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import gc\n",
        "import torch.optim as optim\n",
        "from torch.nn import BCELoss\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqPtSJC7VG5Q"
      },
      "source": [
        "#GIF SAVER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUZRmgH8VIlh"
      },
      "outputs": [],
      "source": [
        "import imageio.v2 as imageio\n",
        "\n",
        "def create_gif(display_function, frames_range, filename=\"visualization.gif\", fps=5):\n",
        "    \"\"\"\n",
        "    Creates a GIF from an interactive visualization.\n",
        "\n",
        "    Args:\n",
        "        display_function: The function that generates the visualization for a given slice index.\n",
        "        frames_range: A range or list of slice indices to include in the GIF.\n",
        "        filename: The name of the output GIF file.\n",
        "        fps: Frames per second for the GIF.\n",
        "    \"\"\"\n",
        "\n",
        "    frames = []\n",
        "    for slice_index in frames_range:\n",
        "        print(slice_index)\n",
        "        # Call the display function to generate the plot\n",
        "        display_function(slice_index)\n",
        "        plt.savefig(f\"frame_{slice_index}.png\")\n",
        "        plt.close()\n",
        "        frames.append(f\"frame_{slice_index}.png\")\n",
        "\n",
        "    imageio.mimsave(filename, [imageio.imread(f) for f in frames], fps=fps)\n",
        "\n",
        "    # Clean up temporary frame files\n",
        "    for f in frames:\n",
        "        os.remove(f)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMyoEI4VoCly"
      },
      "source": [
        "# MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_Qfs87hehG6"
      },
      "outputs": [],
      "source": [
        "class DownCNNBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, use_padding=False):\n",
        "        super(DownCNNBlock, self).__init__()\n",
        "        padding = 1 if use_padding else 0\n",
        "\n",
        "        # Two 3x3x3 convolutional layers with ReLU activation\n",
        "        self.conv1 = nn.Conv3d(in_channels, out_channels, kernel_size=(3, 3, 3), padding=padding)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.conv2 = nn.Conv3d(out_channels, out_channels, kernel_size=(3, 3, 3), padding=padding)\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "        # 2x2x2 max pooling for downsampling\n",
        "        self.pooling = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=2)\n",
        "\n",
        "    def forward(self, input):\n",
        "        # print(\"DownCNNBLOCK\")\n",
        "        res = self.relu1(self.conv1(input))\n",
        "        res = self.relu2(self.conv2(res))\n",
        "        out = self.pooling(res)\n",
        "        return out, res\n",
        "\n",
        "class UpCNNBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, last_layer=False):\n",
        "        super(UpCNNBlock, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "\n",
        "        # 2x2x2 transposed convolution for upsampling\n",
        "        self.upconv = nn.ConvTranspose3d(in_channels - out_channels, in_channels - out_channels, kernel_size=(2, 2, 2), stride=2)\n",
        "        self.finalUpconv = nn.ConvTranspose3d(in_channels, in_channels, kernel_size=(2, 2, 2), stride=2)\n",
        "\n",
        "        # Two 3x3x3 convolutional layers with ReLU activation\n",
        "        self.conv1 = nn.Conv3d(in_channels + out_channels, out_channels, kernel_size=(3, 3, 3), padding=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.conv2 = nn.Conv3d(out_channels, out_channels, kernel_size=(3, 3, 3), padding=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.conv1Final = nn.Conv3d(in_channels + in_channels, out_channels, kernel_size=(3, 3, 3), padding=1)\n",
        "\n",
        "        # Flag to indicate if this is the last layer\n",
        "        self.last_layer = last_layer\n",
        "\n",
        "        # If it's the last layer, add a 1x1x1 convolution and sigmoid activation\n",
        "        self.conv3 = nn.Conv3d(out_channels, 1, kernel_size=(1, 1, 1))\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, input, residual=None):\n",
        "        # Apply transposed convolution for upsampling\n",
        "        if self.out_channels == 1:\n",
        "            out = self.finalUpconv(input)\n",
        "        else:\n",
        "            out = self.upconv(input)\n",
        "        if residual is not None:\n",
        "            if len(out.shape) == 4:\n",
        "                out = torch.cat((out, residual), dim=0)\n",
        "            else:\n",
        "              out = torch.cat((out, residual), dim=1) #!!!!!!!!!!!\n",
        "\n",
        "        # Apply convolutions and activations\n",
        "        if self.out_channels == 1:\n",
        "            out = self.conv1Final(out)\n",
        "        else:\n",
        "            out = self.relu1(self.conv1(out))\n",
        "\n",
        "        out = self.relu2(self.conv2(out))\n",
        "        # Apply final convolution and sigmoid if it's the last layer\n",
        "        if self.last_layer:\n",
        "            out = self.conv3(out)\n",
        "            out = self.sigmoid(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class UNet3D(nn.Module):\n",
        "    def __init__(self, in_channels, level_channels=[16, 32, 64]):\n",
        "        super(UNet3D, self).__init__()\n",
        "        self.a_block1 = DownCNNBlock(in_channels, level_channels[0], use_padding=True)\n",
        "        self.a_block2 = DownCNNBlock(level_channels[0], level_channels[1], use_padding=True)\n",
        "        self.a_block3 = DownCNNBlock(level_channels[1], level_channels[2], use_padding=True)\n",
        "\n",
        "        self.s_block3 = UpCNNBlock(level_channels[2] + level_channels[1], level_channels[1])\n",
        "        self.s_block2 = UpCNNBlock(level_channels[1] + level_channels[0], level_channels[0])\n",
        "        self.s_block1 = UpCNNBlock(level_channels[0], in_channels, last_layer=True)\n",
        "\n",
        "    def forward(self, input):\n",
        "        out1, res1 = self.a_block1(input)\n",
        "        out2, res2 = self.a_block2(out1)\n",
        "        out3, res3 = self.a_block3(out2)\n",
        "\n",
        "        out = self.s_block3(out3, res3)\n",
        "        out = self.s_block2(out, res2)\n",
        "        out = self.s_block1(out, res1)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWL1B8TD71uc"
      },
      "outputs": [],
      "source": [
        "def dice_loss(prediction, target, smooth=1e-5):\n",
        "    prediction = prediction.view(-1)\n",
        "    target = target.view(-1)\n",
        "\n",
        "    intersection = (prediction * target).sum()\n",
        "    union = prediction.sum() + target.sum()\n",
        "\n",
        "    dice = (2. * intersection + smooth) / (union + smooth)\n",
        "\n",
        "    return 1.0 - dice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87wV9cQIzIL6"
      },
      "source": [
        "# DATA LOADING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QRN2hM4gFUSM"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tr6ciECbrVbo"
      },
      "outputs": [],
      "source": [
        "input_dir = '/content/drive/MyDrive/BinaryAirwaySegmentation/1.3.6.1.4.1.14519.5.2.1.6279.6001.221945191226273284587353530424/Input'\n",
        "mask_path = '/content/drive/MyDrive/BinaryAirwaySegmentation/1.3.6.1.4.1.14519.5.2.1.6279.6001.221945191226273284587353530424/Mask/1.3.6.1.4.1.14519.5.2.1.6279.6001.221945191226273284587353530424.nii.gz'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3f2QHQGr8pt"
      },
      "outputs": [],
      "source": [
        "dcm_files = [os.path.join(input_dir, f) for f in os.listdir(input_dir) if f.endswith('.dcm')]\n",
        "dcm_files.sort(key=lambda f: pydicom.dcmread(f).SliceLocation)\n",
        "\n",
        "input_volume = []\n",
        "for file in dcm_files:\n",
        "    ds = pydicom.dcmread(file)\n",
        "    input_volume.append(ds.pixel_array)\n",
        "\n",
        "input_volume = np.stack(input_volume, axis=0)\n",
        "mask_volume = nib.load(mask_path).get_fdata()\n",
        "mask_volume = np.asarray(mask_volume)\n",
        "mask_volume = np.rot90(mask_volume, k=1, axes=(0, 1))\n",
        "mask_volume = np.flip(mask_volume, axis=0)\n",
        "mask_volume = np.moveaxis(mask_volume, -1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_C3z65hDsk-i"
      },
      "outputs": [],
      "source": [
        "def display_slices(slice_index):\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))  # Create a figure with 2 subplots\n",
        "\n",
        "    # Display input_volume slice\n",
        "    axes[0].imshow(input_volume[slice_index], cmap='gray')\n",
        "    axes[0].set_title(f\"Input Slice {slice_index}\")\n",
        "\n",
        "    # Display mask_volume slice\n",
        "    axes[1].imshow(mask_volume[slice_index], cmap='gray')  # Assuming mask is grayscale\n",
        "    axes[1].set_title(f\"Mask Slice {slice_index}\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Create an interactive slider\n",
        "interact(display_slices, slice_index=IntSlider(min=0, max=input_volume.shape[0] - 1, step=1, value=0))\n",
        "# create_gif(display_slices, range(input_volume.shape[0] - 1), filename=\"DATA.gif\", fps=25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIt-YLRRh-ne"
      },
      "source": [
        "# OLD DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1VIUURw2zL-"
      },
      "outputs": [],
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, input_volume, mask_volume):\n",
        "        self.input_volume = torch.from_numpy(input_volume).float()  # Shape: (depth, height, width)\n",
        "        self.mask_volume = torch.from_numpy(mask_volume).float()  # Shape: (depth, height, width)\n",
        "\n",
        "    def __len__(self):\n",
        "        return 1  # Since we're loading the whole volume\n",
        "\n",
        "    def __getitem__(self, idx):  # Removed idx\n",
        "        input_volume = self.input_volume[np.newaxis, ...]  # Shape: (1, depth, height, width)\n",
        "        mask_volume = self.mask_volume[np.newaxis, ...]  # Shape: (1, depth, height, width)\n",
        "        return input_volume, mask_volume\n",
        "\n",
        "    def get_patch(self, center_coords, patch_size=128):\n",
        "        d, w, h = center_coords\n",
        "        d_start = d - patch_size // 2\n",
        "        h_start = h - patch_size // 2\n",
        "        w_start = w - patch_size // 2\n",
        "        input_patch = self.input_volume[d_start : d_start + patch_size,\n",
        "                                        h_start : h_start + patch_size,\n",
        "                                        w_start : w_start + patch_size,]\n",
        "        mask_patch = self.mask_volume[d_start : d_start + patch_size,\n",
        "                                      h_start : h_start + patch_size,\n",
        "                                      w_start : w_start + patch_size,]\n",
        "        input_patch = input_patch[np.newaxis, ...]  # Shape: (1, depth, height, width)\n",
        "        mask_patch = mask_patch[np.newaxis, ...]  # Shape: (1, depth, height, width)\n",
        "\n",
        "        return input_patch, mask_patch\n",
        "\n",
        "    def get_random_patch(self, patch_size=128):\n",
        "        d = np.random.randint(patch_size // 2, self.input_volume.shape[0] - patch_size // 2 - 1)\n",
        "        h = np.random.randint(patch_size // 2, self.input_volume.shape[1] - patch_size // 2 - 1)\n",
        "        w = np.random.randint(patch_size // 2, self.input_volume.shape[2] - patch_size // 2 - 1)\n",
        "\n",
        "        input_patch, mask_patch = self.get_patch(center_coords=(d, h, w), patch_size=patch_size)\n",
        "        return input_patch, mask_patch\n",
        "\n",
        "    def get_patches(self, num_patches, patch_size=128):\n",
        "        input_patches = []\n",
        "        mask_patches = []\n",
        "\n",
        "        for _ in range(num_patches):\n",
        "            while True:\n",
        "                input_patch, mask_patch = self.get_random_patch(patch_size=patch_size)\n",
        "                c = torch.sum(mask_patch)\n",
        "                if c > 500:\n",
        "                    # print(f\"good patch | count of {c}\")\n",
        "                    break\n",
        "                  # print(\"x\", end=\"\")\n",
        "                  # print(f\"empty patch, generating new patch | count of {c}\")\n",
        "            # print(\"\")\n",
        "            # print(f\"count of {c}\")\n",
        "            input_patches.append(input_patch)\n",
        "            mask_patches.append(mask_patch)\n",
        "\n",
        "        # Stack patches into a batch\n",
        "        input_patches = np.stack(input_patches, axis=0)\n",
        "        mask_patches = np.stack(mask_patches, axis=0)\n",
        "\n",
        "        return input_patches, mask_patches\n",
        "\n",
        "    def visualize_patch(self, input_patch, mask_patch, slice_index=16):  # Default to center slice\n",
        "        def display_slices(slice_index):\n",
        "            fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
        "\n",
        "            # Display input patch slice\n",
        "            axes[0].imshow(input_patch[0][slice_index], cmap='gray')\n",
        "            axes[0].set_title(f\"Input Patch Slice {slice_index}\")\n",
        "\n",
        "            # Display mask patch slice\n",
        "            axes[1].imshow(mask_patch[0][slice_index], cmap='gray')\n",
        "            axes[1].set_title(f\"Mask Patch Slice {slice_index}\")\n",
        "\n",
        "            plt.show()\n",
        "\n",
        "        # Create an interactive slider\n",
        "        interact(display_slices, slice_index=IntSlider(min=0, max=input_patch.shape[1] - 1, step=1, value=input_patch.shape[1] // 2))\n",
        "        # create_gif(display_slices, range(input_patch.shape[1] - 1), filename=\"PATCH.gif\", fps=25)\n",
        "\n",
        "# Create dataset instance\n",
        "# dataset = MyDataset(input_volume, mask_volume)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "epxGr4_TQAXq"
      },
      "outputs": [],
      "source": [
        "test_input_dir = '/content/drive/MyDrive/BinaryAirwaySegmentation/1.3.6.1.4.1.14519.5.2.1.6279.6001.221945191226273284587353530424/Input'\n",
        "test_mask_path = '/content/drive/MyDrive/BinaryAirwaySegmentation/1.3.6.1.4.1.14519.5.2.1.6279.6001.221945191226273284587353530424/Mask/1.3.6.1.4.1.14519.5.2.1.6279.6001.221945191226273284587353530424.nii.gz'\n",
        "\n",
        "# Load data and create dataset object\n",
        "dcm_files = [os.path.join(test_input_dir, f) for f in os.listdir(test_input_dir) if f.endswith('.dcm')]\n",
        "dcm_files.sort(key=lambda f: pydicom.dcmread(f).SliceLocation)\n",
        "\n",
        "test_input_volume = []\n",
        "for file in dcm_files:\n",
        "    ds = pydicom.dcmread(file)\n",
        "    test_input_volume.append(ds.pixel_array)\n",
        "\n",
        "test_input_volume = np.stack(input_volume, axis=0)\n",
        "test_mask_volume = nib.load(test_mask_path).get_fdata()\n",
        "test_mask_volume = np.asarray(test_mask_volume)\n",
        "test_mask_volume = np.rot90(test_mask_volume, k=1, axes=(0, 1))\n",
        "test_mask_volume = np.flip(test_mask_volume, axis=0)\n",
        "test_mask_volume = np.moveaxis(test_mask_volume, -1, 0)\n",
        "\n",
        "test_dataset = MyDataset(test_input_volume, test_mask_volume)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHTsh5Q_92EG"
      },
      "outputs": [],
      "source": [
        "model = UNet3D(in_channels=1).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TOwSmjPVQImZ"
      },
      "outputs": [],
      "source": [
        "# Save the model\n",
        "model_save_path = '/content/drive/MyDrive/MODEL.pth'  # Replace with your desired path and filename\n",
        "torch.save(model.state_dict(), model_save_path)\n",
        "# model.load_state_dict(torch.load(model_save_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EhHAMirfwBWn"
      },
      "outputs": [],
      "source": [
        "example_patches, example_masks = dataset.get_patches(num_patches=1)\n",
        "example_patch = example_patches[0]\n",
        "example_mask = example_masks[0]\n",
        "dataset.visualize_patch(example_patch, example_mask)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21IuhD4ULUms"
      },
      "outputs": [],
      "source": [
        "# Optimizer and loss function\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "# criterion = BCELoss()\n",
        "# criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([150.0])).to(device)\n",
        "criterion = dice_loss\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 100\n",
        "batch_size = 5\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    input_patches, mask_patches = dataset.get_patches(num_patches=batch_size)\n",
        "    input_patches = torch.from_numpy(input_patches).to(device)\n",
        "    mask_patches = torch.from_numpy(mask_patches).to(device)\n",
        "\n",
        "    optimizer.zero_grad()  # Reset gradients\n",
        "    output = model(input_patches)  # Forward pass\n",
        "    loss = criterion(output, mask_patches)  # Calculate loss\n",
        "    loss.backward()  # Backpropagate gradients\n",
        "    optimizer.step()  # Update model weights\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fK9MtlUUlwY3"
      },
      "outputs": [],
      "source": [
        "input_patch, mask_patch = dataset.get_patch((500,190,250), patch_size=128)\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "with torch.no_grad():\n",
        "    output = model(input_patch)\n",
        "\n",
        "# dataset.visualize_patch(input_patch, mask_patch)\n",
        "o, m, i = output, mask_patch, input_patch\n",
        "x = o[0,:].numpy()\n",
        "z = i[0,:].numpy()\n",
        "\n",
        "o_min, o_max = x.min(), x.max()\n",
        "i_min, i_max = z.min(), z.max()\n",
        "\n",
        "def display_slices2(slice_index):\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))  # Adjust figsize for colorbar space\n",
        "    # Display input_volume slice with colorbar\n",
        "    im1 = axes[0].imshow(o[0][slice_index], cmap='jet',vmin=o_min, vmax=o_max)\n",
        "    fig.colorbar(im1, ax=axes[0], fraction=0.046, pad=0.04)  # Add colorbar to axes[0]\n",
        "    axes[0].set_title(f\"Output Slice {slice_index}\")\n",
        "\n",
        "    # Display mask_patch slice with colorbar\n",
        "    im2 = axes[1].imshow(m[0][slice_index], cmap='jet',vmin=0.0, vmax=1.0)\n",
        "    fig.colorbar(im2, ax=axes[1], fraction=0.046, pad=0.04)  # Add colorbar to axes[1]\n",
        "    axes[1].set_title(f\"Mask Slice {slice_index}\")\n",
        "\n",
        "    # Display input_patch slice with colorbar\n",
        "    im3 = axes[2].imshow(i[0][slice_index], cmap='jet',vmin=i_min, vmax=i_max)\n",
        "    fig.colorbar(im3, ax=axes[2], fraction=0.046, pad=0.04)  # Add colorbar to axes[2]\n",
        "    axes[2].set_title(f\"Input Slice {slice_index}\")\n",
        "\n",
        "    plt.show()\n",
        "# Create an interactive slider (adjust max value if needed)\n",
        "max_index = int(output.shape[1] - 1)\n",
        "interact(display_slices2, slice_index=IntSlider(min=0, max=127, step=1, value=0))\n",
        "# create_gif(display_slices2, range(127), filename=\"OUTPUT.gif\", fps=25)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3yZac6FLNQNB"
      },
      "outputs": [],
      "source": [
        "# Load your trained model\n",
        "model.eval()\n",
        "\n",
        "# Number of patches to test on\n",
        "num_patches = 1 # You can adjust this number\n",
        "\n",
        "# Lists to store predictions and ground truths for accuracy calculation\n",
        "confusion_matrix = torch.zeros(2, 2, dtype=torch.int32)  # 2x2 for binary classification\n",
        "\n",
        "# Test loop\n",
        "with torch.no_grad():\n",
        "    for _ in range(num_patches):\n",
        "        # Get a random patch\n",
        "        # one example\n",
        "        input_patch, mask_patch = dataset.get_patch((500,190,250), patch_size=128)\n",
        "\n",
        "        # Make prediction\n",
        "        output = model(input_patch.float().to(device))\n",
        "        output = torch.sigmoid(output)  # Apply sigmoid for probabilities\n",
        "\n",
        "        # Convert to binary predictions (threshold at 0.5)\n",
        "        predictions = (output > 0.5).int().cpu().numpy().flatten()\n",
        "        ground_truth = mask_patch.int().cpu().numpy().flatten()\n",
        "\n",
        "        # Update confusion matrix\n",
        "        for p, t in zip(predictions, ground_truth):\n",
        "            confusion_matrix[t, p] += 1\n",
        "\n",
        "# Display confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.imshow(confusion_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.colorbar()\n",
        "\n",
        "# Add labels to the plot\n",
        "classes = ['Background', 'Airway']\n",
        "tick_marks = np.arange(len(classes))\n",
        "plt.xticks(tick_marks, classes, rotation=45)\n",
        "plt.yticks(tick_marks, classes)\n",
        "\n",
        "# Add text annotations inside the plot\n",
        "thresh = confusion_matrix.max() / 2.\n",
        "for i, j in np.ndindex(confusion_matrix.shape):\n",
        "    plt.text(j, i, format(confusion_matrix[i, j].item(), 'd'),\n",
        "             horizontalalignment=\"center\",\n",
        "             color=\"white\" if confusion_matrix[i, j] > thresh else \"black\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zw8IFOB_UJLS"
      },
      "outputs": [],
      "source": [
        "input_patch, mask_patch = dataset.get_patch((125,150,150), patch_size=128)\n",
        "with torch.no_grad():\n",
        "    output2 = model(input_patch)\n",
        "    output2 = torch.sigmoid(output2)\n",
        "\n",
        "# Visualize the patch (slice 16 by default)\n",
        "# dataset.visualize_patch(input_patch, mask_patch)\n",
        "o2, m2, i2 = output2, mask_patch, input_patch\n",
        "x2 = o2[0,:].numpy()\n",
        "z2 = i2[0,:].numpy()\n",
        "\n",
        "o_min2, o_max2 = x2.min(), x2.max()\n",
        "i_min2, i_max2 = z2.min(), z2.max()\n",
        "\n",
        "def display_slices3(slice_index):\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))  # Adjust figsize for colorbar space\n",
        "    # Display input_volume slice with colorbar\n",
        "    im1 = axes[0].imshow(o2[0][slice_index], cmap='jet',vmin=o_min2, vmax=o_max2)\n",
        "    fig.colorbar(im1, ax=axes[0], fraction=0.046, pad=0.04)  # Add colorbar to axes[0]\n",
        "    axes[0].set_title(f\"Output Slice {slice_index}\")\n",
        "\n",
        "    # Display mask_patch slice with colorbar\n",
        "    im2 = axes[1].imshow(m2[0][slice_index], cmap='jet',vmin=0.0, vmax=1.0)\n",
        "    fig.colorbar(im2, ax=axes[1], fraction=0.046, pad=0.04)  # Add colorbar to axes[1]\n",
        "    axes[1].set_title(f\"Mask Slice {slice_index}\")\n",
        "\n",
        "    # Display input_patch slice with colorbar\n",
        "    im3 = axes[2].imshow(i2[0][slice_index], cmap='jet',vmin=i_min2, vmax=i_max2)\n",
        "    fig.colorbar(im3, ax=axes[2], fraction=0.046, pad=0.04)  # Add colorbar to axes[2]\n",
        "    axes[2].set_title(f\"Input Slice {slice_index}\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Create an interactive slider (adjust max value if needed)\n",
        "max_index = int(output2.shape[1] - 1)\n",
        "interact(display_slices3, slice_index=IntSlider(min=0, max=127, step=1, value=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcJGjzmHzNCj"
      },
      "source": [
        "# NEW DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGFN2cq_zZuC"
      },
      "outputs": [],
      "source": [
        "class PatchLoader:\n",
        "    def __init__(self, drive_dir, num_patches_per_volume=5, patch_size=128):\n",
        "        self.drive_dir = drive_dir\n",
        "        self.num_patches_per_volume = num_patches_per_volume\n",
        "        self.patch_size = patch_size\n",
        "        self.data_folders = self.get_data_folders()\n",
        "\n",
        "        self.input_patches = []\n",
        "        self.mask_patches = []\n",
        "        self.load_and_extract_patches()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_patches)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_patch = torch.from_numpy(self.input_patches[idx]).float()\n",
        "        mask_patch = torch.from_numpy(self.mask_patches[idx]).float()\n",
        "        return input_patch, mask_patch\n",
        "\n",
        "    def visualize_sample_patches(self, num_samples=5):\n",
        "        indices = np.random.choice(len(self.input_patches), num_samples, replace=False)\n",
        "        sample_input_patches = [self.input_patches[i] for i in indices]\n",
        "        sample_mask_patches = [self.mask_patches[i] for i in indices]\n",
        "\n",
        "        def display_slices(slice_index):\n",
        "            num_cols = num_samples\n",
        "            num_rows = 2\n",
        "            fig, axes = plt.subplots(num_rows, num_cols, figsize=(10, 5 * num_rows))\n",
        "\n",
        "            for i in range(num_samples):\n",
        "                axes[0, i].imshow(sample_input_patches[i][0][slice_index], cmap='gray')\n",
        "                axes[0, i].set_title(f\"Input, Patch {i + 1}, Slice {slice_index}\")\n",
        "\n",
        "                axes[1, i].imshow(sample_mask_patches[i][0][slice_index], cmap='gray')\n",
        "                axes[1, i].set_title(f\"Mask, Patch {i + 1}, Slice {slice_index}\")\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "        # Create interactive slider\n",
        "        slice_slider = IntSlider(min=0, max=sample_input_patches[0].shape[1] - 1, step=1, value=0)\n",
        "        interact(display_slices, slice_index=slice_slider)\n",
        "\n",
        "    def get_patches(self):\n",
        "        return self.input_patches, self.mask_patches\n",
        "\n",
        "    def get_data_folders(self):\n",
        "        data_folders = [os.path.join(self.drive_dir, f) for f in os.listdir(self.drive_dir) if os.path.isdir(os.path.join(self.drive_dir, f))]\n",
        "        return data_folders[:30]\n",
        "\n",
        "    def load_and_extract_patches(self):\n",
        "        input_patches = []\n",
        "        mask_patches = []\n",
        "\n",
        "        for folder in tqdm(self.data_folders, desc=\"Processing Volumes\"):\n",
        "            print(f\"\\n{folder}\")\n",
        "            input_dir = os.path.join(folder, 'Input')\n",
        "            mask_path = os.path.join(folder, 'Mask', os.listdir(os.path.join(folder, 'Mask'))[0])  # Assuming only one mask file\n",
        "            dcm_files = [os.path.join(input_dir, f) for f in os.listdir(input_dir) if f.endswith('.dcm')]\n",
        "            dcm_files.sort(key=lambda f: pydicom.dcmread(f).SliceLocation)\n",
        "\n",
        "            input_volume = []\n",
        "            for file in dcm_files:\n",
        "                ds = pydicom.dcmread(file)\n",
        "                input_volume.append(ds.pixel_array)\n",
        "            input_volume = np.stack(input_volume, axis=0)\n",
        "\n",
        "            mask_volume = nib.load(mask_path).get_fdata()\n",
        "            mask_volume = np.asarray(mask_volume)\n",
        "            mask_volume = np.rot90(mask_volume, k=1, axes=(0, 1))\n",
        "            mask_volume = np.flip(mask_volume, axis=0)\n",
        "            mask_volume = np.moveaxis(mask_volume, -1, 0)\n",
        "\n",
        "            for _ in tqdm(range(self.num_patches_per_volume)):\n",
        "                count = 0\n",
        "                if np.random.rand() < 0.75:\n",
        "                    while True:\n",
        "                        input_patch, mask_patch = self.get_random_patch_from_volume(input_volume, mask_volume)\n",
        "                        c = np.sum(mask_patch)\n",
        "                        if c > 500:\n",
        "                            break\n",
        "                        count += 1\n",
        "                        if count == 1000:\n",
        "                            break\n",
        "                else:\n",
        "                    input_patch, mask_patch = self.get_random_patch_from_volume(input_volume, mask_volume)\n",
        "\n",
        "                input_patches.append(input_patch)\n",
        "                mask_patches.append(mask_patch)\n",
        "            del input_volume, mask_volume\n",
        "            gc.collect()\n",
        "            print(f\"total nums of patches is {len(input_patches)}\")\n",
        "\n",
        "        self.input_patches, self.mask_patches = input_patches, mask_patches\n",
        "\n",
        "    def get_random_patch_from_volume(self, input_volume, mask_volume):\n",
        "        patch_size = self.patch_size\n",
        "\n",
        "        d = np.random.randint(patch_size // 2, input_volume.shape[0] - patch_size // 2 - 1)\n",
        "        h = np.random.randint(patch_size // 2, input_volume.shape[1] - patch_size // 2 - 1)\n",
        "        w = np.random.randint(patch_size // 2, input_volume.shape[2] - patch_size // 2 - 1)\n",
        "\n",
        "        input_patch = input_volume[d - patch_size // 2:d + patch_size // 2,\n",
        "                                    h - patch_size // 2:h + patch_size // 2,\n",
        "                                    w - patch_size // 2:w + patch_size // 2]\n",
        "        mask_patch = mask_volume[d - patch_size // 2:d + patch_size // 2,\n",
        "                                  h - patch_size // 2:h + patch_size // 2,\n",
        "                                  w - patch_size // 2:w + patch_size // 2]\n",
        "\n",
        "        input_patch = input_patch[np.newaxis, ...]  # Shape: (1, depth, height, width)\n",
        "        mask_patch = mask_patch[np.newaxis, ...]  # Shape: (1, depth, height, width)\n",
        "\n",
        "        return input_patch, mask_patch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5UPGURTzzrMz"
      },
      "outputs": [],
      "source": [
        "# Assuming you have a list of data folder paths in 'data_folders'\n",
        "drive_dir = '/content/drive/MyDrive/lung'\n",
        "patch_loader = PatchLoader(drive_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZ2ZfJ-5ERO0"
      },
      "outputs": [],
      "source": [
        "input_patches, mask_patches = patch_loader.get_patches()\n",
        "input_patches = torch.tensor(input_patches, dtype=torch.float32).to(device)\n",
        "mask_patches = torch.tensor(mask_patches, dtype=torch.float32).to(device)\n",
        "patch_loader.visualize_sample_patches()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81-CGkdeWzw6"
      },
      "outputs": [],
      "source": [
        "model2 = UNet3D(in_channels=1)\n",
        "model2.load_state_dict(torch.load('/content/drive/MyDrive/NEW_MODEL2.pth'))\n",
        "model2.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IOgET7nm1aCT"
      },
      "outputs": [],
      "source": [
        "# Training loop\n",
        "num_epochs = 1000\n",
        "batch_size = 10  # Adjust as needed\n",
        "optimizer = optim.Adam(model2.parameters(), lr=1e-3)\n",
        "scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "# criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([100.0])).to(device)\n",
        "criterion = dice_loss\n",
        "save_epochs = 5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model2.train()\n",
        "\n",
        "    # Create 2shuffled indices for this epoch\n",
        "    num_samples = len(input_patches)\n",
        "    indices = torch.randperm(num_samples)\n",
        "    if (epoch + 1) % save_epochs == 0:\n",
        "        model_save_path = '/content/drive/MyDrive/NEW_MODEL2.pth'  # Replace with your desired path and filename\n",
        "        torch.save(model2.state_dict(), model_save_path)\n",
        "        print(f\"Model saved at epoch {epoch}\\n\")\n",
        "\n",
        "    for batch_start in range(0, num_samples, batch_size):\n",
        "        # Get batch indices\n",
        "        batch_indices = indices[batch_start : batch_start + batch_size]\n",
        "\n",
        "        # Get input and mask batches\n",
        "        input_batch = input_patches[batch_indices].to(device) #Move to device here to reduce memory footprint\n",
        "        mask_batch = mask_patches[batch_indices].to(device)  #Move to device here to reduce memory footprint\n",
        "\n",
        "        # Training steps:\n",
        "        optimizer.zero_grad()\n",
        "        output = model2(input_batch)\n",
        "        loss = criterion(output, mask_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}], Batch [{batch_start // batch_size + 1}/{num_samples // batch_size}], Loss: {loss.item():.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z6p6y8NPW7X2"
      },
      "outputs": [],
      "source": [
        "model_save_path = '/content/drive/MyDrive/NEW_MODEL2.pth'  # Replace with your desired path and filename\n",
        "torch.save(model2.state_dict(), model_save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wr4xm_x0GviB"
      },
      "outputs": [],
      "source": [
        "input_dir = '/content/drive/MyDrive/lung/1.3.6.1.4.1.14519.5.2.1.6279.6001.221945191226273284587353530424/Input'\n",
        "mask_path = '/content/drive/MyDrive/lung/1.3.6.1.4.1.14519.5.2.1.6279.6001.221945191226273284587353530424/Mask/1.3.6.1.4.1.14519.5.2.1.6279.6001.221945191226273284587353530424.nii.gz'\n",
        "\n",
        "dcm_files = [os.path.join(input_dir, f) for f in os.listdir(input_dir) if f.endswith('.dcm')]\n",
        "dcm_files.sort(key=lambda f: pydicom.dcmread(f).SliceLocation)\n",
        "\n",
        "input_volume = []\n",
        "for file in dcm_files:\n",
        "    ds = pydicom.dcmread(file)\n",
        "    input_volume.append(ds.pixel_array)\n",
        "\n",
        "input_volume = np.stack(input_volume, axis=0)\n",
        "mask_volume = nib.load(mask_path).get_fdata()\n",
        "mask_volume = np.asarray(mask_volume)\n",
        "mask_volume = np.rot90(mask_volume, k=1, axes=(0, 1))\n",
        "mask_volume = np.flip(mask_volume, axis=0)\n",
        "mask_volume = np.moveaxis(mask_volume, -1, 0)\n",
        "\n",
        "dataset = MyDataset(input_volume, mask_volume)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9bgISadCX1h"
      },
      "outputs": [],
      "source": [
        "input_patch, mask_patch = dataset.get_patch((496,190,253), patch_size=128)\n",
        "model2.eval()  # Set the model to evaluation mode\n",
        "with torch.no_grad():\n",
        "    output = model2(input_patch)\n",
        "    # output = torch.sigmoid(output)\n",
        "\n",
        "# Visualize the patch (slice 16 by default)\n",
        "# dataset.visualize_patch(input_patch, mask_patch)\n",
        "o, m, i = output, mask_patch, input_patch\n",
        "x = o[0,:].numpy()\n",
        "z = i[0,:].numpy()\n",
        "\n",
        "o_min, o_max = x.min(), x.max()\n",
        "i_min, i_max = z.min(), z.max()\n",
        "\n",
        "def display_slices(slice_index):\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))  # Adjust figsize for colorbar space\n",
        "    # Display input_volume slice with colorbar\n",
        "    im1 = axes[0].imshow(o[0][slice_index], cmap='jet',vmin=o_min, vmax=o_max)\n",
        "    fig.colorbar(im1, ax=axes[0], fraction=0.046, pad=0.04)  # Add colorbar to axes[0]\n",
        "    axes[0].set_title(f\"Output Slice {slice_index}\")\n",
        "\n",
        "    # Display mask_patch slice with colorbar\n",
        "    im2 = axes[1].imshow(m[0][slice_index], cmap='jet',vmin=0.0, vmax=1.0)\n",
        "    fig.colorbar(im2, ax=axes[1], fraction=0.046, pad=0.04)  # Add colorbar to axes[1]\n",
        "    axes[1].set_title(f\"Mask Slice {slice_index}\")\n",
        "\n",
        "    # Display input_patch slice with colorbar\n",
        "    im3 = axes[2].imshow(i[0][slice_index], cmap='jet',vmin=i_min, vmax=i_max)\n",
        "    fig.colorbar(im3, ax=axes[2], fraction=0.046, pad=0.04)  # Add colorbar to axes[2]\n",
        "    axes[2].set_title(f\"Input Slice {slice_index}\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Create an interactive slider (adjust max value if needed)\n",
        "max_index = int(output.shape[1] - 1)\n",
        "interact(display_slices, slice_index=IntSlider(min=0, max=127, step=1, value=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RUN ALL\n"
      ],
      "metadata": {
        "id": "0fkfyPC7RFZO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydicom\n",
        "!pip install nibabel\n",
        "\n",
        "from torch import nn\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from ipywidgets import interact, IntSlider\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import pydicom\n",
        "import nibabel as nib\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import gc\n",
        "import torch.optim as optim\n",
        "from torch.nn import BCELoss\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "Qqi048e-RHnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DownCNNBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, use_padding=False):\n",
        "        super(DownCNNBlock, self).__init__()\n",
        "        padding = 1 if use_padding else 0\n",
        "\n",
        "        # Two 3x3x3 convolutional layers with ReLU activation\n",
        "        self.conv1 = nn.Conv3d(in_channels, out_channels, kernel_size=(3, 3, 3), padding=padding)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.conv2 = nn.Conv3d(out_channels, out_channels, kernel_size=(3, 3, 3), padding=padding)\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "        # 2x2x2 max pooling for downsampling\n",
        "        self.pooling = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=2)\n",
        "\n",
        "    def forward(self, input):\n",
        "        # print(\"DownCNNBLOCK\")\n",
        "        res = self.relu1(self.conv1(input))\n",
        "        res = self.relu2(self.conv2(res))\n",
        "        out = self.pooling(res)\n",
        "        return out, res\n",
        "\n",
        "class UpCNNBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, last_layer=False):\n",
        "        super(UpCNNBlock, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "\n",
        "        # 2x2x2 transposed convolution for upsampling\n",
        "        self.upconv = nn.ConvTranspose3d(in_channels - out_channels, in_channels - out_channels, kernel_size=(2, 2, 2), stride=2)\n",
        "        self.finalUpconv = nn.ConvTranspose3d(in_channels, in_channels, kernel_size=(2, 2, 2), stride=2)\n",
        "\n",
        "        # Two 3x3x3 convolutional layers with ReLU activation\n",
        "        self.conv1 = nn.Conv3d(in_channels + out_channels, out_channels, kernel_size=(3, 3, 3), padding=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.conv2 = nn.Conv3d(out_channels, out_channels, kernel_size=(3, 3, 3), padding=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.conv1Final = nn.Conv3d(in_channels + in_channels, out_channels, kernel_size=(3, 3, 3), padding=1)\n",
        "\n",
        "        # Flag to indicate if this is the last layer\n",
        "        self.last_layer = last_layer\n",
        "\n",
        "        # If it's the last layer, add a 1x1x1 convolution and sigmoid activation\n",
        "        self.conv3 = nn.Conv3d(out_channels, 1, kernel_size=(1, 1, 1))\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, input, residual=None):\n",
        "        # Apply transposed convolution for upsampling\n",
        "        if self.out_channels == 1:\n",
        "            out = self.finalUpconv(input)\n",
        "        else:\n",
        "            out = self.upconv(input)\n",
        "        if residual is not None:\n",
        "            if len(out.shape) == 4:\n",
        "                out = torch.cat((out, residual), dim=0)\n",
        "            else:\n",
        "              out = torch.cat((out, residual), dim=1) #!!!!!!!!!!!\n",
        "\n",
        "        # Apply convolutions and activations\n",
        "        if self.out_channels == 1:\n",
        "            out = self.conv1Final(out)\n",
        "        else:\n",
        "            out = self.relu1(self.conv1(out))\n",
        "\n",
        "        out = self.relu2(self.conv2(out))\n",
        "        # Apply final convolution and sigmoid if it's the last layer\n",
        "        if self.last_layer:\n",
        "            out = self.conv3(out)\n",
        "            out = self.sigmoid(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class UNet3D(nn.Module):\n",
        "    def __init__(self, in_channels, level_channels=[16, 32, 64]):\n",
        "        super(UNet3D, self).__init__()\n",
        "        self.a_block1 = DownCNNBlock(in_channels, level_channels[0], use_padding=True)\n",
        "        self.a_block2 = DownCNNBlock(level_channels[0], level_channels[1], use_padding=True)\n",
        "        self.a_block3 = DownCNNBlock(level_channels[1], level_channels[2], use_padding=True)\n",
        "\n",
        "        self.s_block3 = UpCNNBlock(level_channels[2] + level_channels[1], level_channels[1])\n",
        "        self.s_block2 = UpCNNBlock(level_channels[1] + level_channels[0], level_channels[0])\n",
        "        self.s_block1 = UpCNNBlock(level_channels[0], in_channels, last_layer=True)\n",
        "\n",
        "    def forward(self, input):\n",
        "        out1, res1 = self.a_block1(input)\n",
        "        out2, res2 = self.a_block2(out1)\n",
        "        out3, res3 = self.a_block3(out2)\n",
        "\n",
        "        out = self.s_block3(out3, res3)\n",
        "        out = self.s_block2(out, res2)\n",
        "        out = self.s_block1(out, res1)\n",
        "        return out\n",
        "\n",
        "def dice_loss(prediction, target, smooth=1e-5):\n",
        "    prediction = prediction.view(-1)\n",
        "    target = target.view(-1)\n",
        "\n",
        "    intersection = (prediction * target).sum()\n",
        "    union = prediction.sum() + target.sum()\n",
        "\n",
        "    dice = (2. * intersection + smooth) / (union + smooth)\n",
        "\n",
        "    return 1.0 - dice"
      ],
      "metadata": {
        "id": "WV8W_MK9RM9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "vu-p_QCBRPhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchLoader:\n",
        "    def __init__(self, drive_dir, num_patches_per_volume=5, patch_size=128):\n",
        "        self.drive_dir = drive_dir\n",
        "        self.num_patches_per_volume = num_patches_per_volume\n",
        "        self.patch_size = patch_size\n",
        "        self.data_folders = self.get_data_folders()\n",
        "\n",
        "        self.input_patches = []\n",
        "        self.mask_patches = []\n",
        "        self.load_and_extract_patches()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_patches)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_patch = torch.from_numpy(self.input_patches[idx]).float()\n",
        "        mask_patch = torch.from_numpy(self.mask_patches[idx]).float()\n",
        "        return input_patch, mask_patch\n",
        "\n",
        "    def visualize_sample_patches(self, num_samples=5):\n",
        "        indices = np.random.choice(len(self.input_patches), num_samples, replace=False)\n",
        "        sample_input_patches = [self.input_patches[i] for i in indices]\n",
        "        sample_mask_patches = [self.mask_patches[i] for i in indices]\n",
        "\n",
        "        def display_slices(slice_index):\n",
        "            num_cols = num_samples\n",
        "            num_rows = 2\n",
        "            fig, axes = plt.subplots(num_rows, num_cols, figsize=(10, 5 * num_rows))\n",
        "\n",
        "            for i in range(num_samples):\n",
        "                axes[0, i].imshow(sample_input_patches[i][0][slice_index], cmap='gray')\n",
        "                axes[0, i].set_title(f\"Input, Patch {i + 1}, Slice {slice_index}\")\n",
        "\n",
        "                axes[1, i].imshow(sample_mask_patches[i][0][slice_index], cmap='gray')\n",
        "                axes[1, i].set_title(f\"Mask, Patch {i + 1}, Slice {slice_index}\")\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "        # Create interactive slider\n",
        "        slice_slider = IntSlider(min=0, max=sample_input_patches[0].shape[1] - 1, step=1, value=0)\n",
        "        interact(display_slices, slice_index=slice_slider)\n",
        "\n",
        "    def get_patches(self):\n",
        "        return self.input_patches, self.mask_patches\n",
        "\n",
        "    def get_data_folders(self):\n",
        "        data_folders = [os.path.join(self.drive_dir, f) for f in os.listdir(self.drive_dir) if os.path.isdir(os.path.join(self.drive_dir, f))]\n",
        "        return data_folders[:30]\n",
        "\n",
        "    def load_and_extract_patches(self):\n",
        "        input_patches = []\n",
        "        mask_patches = []\n",
        "\n",
        "        for folder in tqdm(self.data_folders, desc=\"Processing Volumes\"):\n",
        "            print(f\"\\n{folder}\")\n",
        "            input_dir = os.path.join(folder, 'Input')\n",
        "            mask_path = os.path.join(folder, 'Mask', os.listdir(os.path.join(folder, 'Mask'))[0])  # Assuming only one mask file\n",
        "            dcm_files = [os.path.join(input_dir, f) for f in os.listdir(input_dir) if f.endswith('.dcm')]\n",
        "            dcm_files.sort(key=lambda f: pydicom.dcmread(f).SliceLocation)\n",
        "\n",
        "            input_volume = []\n",
        "            for file in dcm_files:\n",
        "                ds = pydicom.dcmread(file)\n",
        "                input_volume.append(ds.pixel_array)\n",
        "            input_volume = np.stack(input_volume, axis=0)\n",
        "\n",
        "            mask_volume = nib.load(mask_path).get_fdata()\n",
        "            mask_volume = np.asarray(mask_volume)\n",
        "            mask_volume = np.rot90(mask_volume, k=1, axes=(0, 1))\n",
        "            mask_volume = np.flip(mask_volume, axis=0)\n",
        "            mask_volume = np.moveaxis(mask_volume, -1, 0)\n",
        "\n",
        "            for _ in tqdm(range(self.num_patches_per_volume)):\n",
        "                count = 0\n",
        "                if np.random.rand() < 0.75:\n",
        "                    while True:\n",
        "                        input_patch, mask_patch = self.get_random_patch_from_volume(input_volume, mask_volume)\n",
        "                        c = np.sum(mask_patch)\n",
        "                        if c > 500:\n",
        "                            break\n",
        "                        count += 1\n",
        "                        if count == 1000:\n",
        "                            break\n",
        "                else:\n",
        "                    input_patch, mask_patch = self.get_random_patch_from_volume(input_volume, mask_volume)\n",
        "\n",
        "                input_patches.append(input_patch)\n",
        "                mask_patches.append(mask_patch)\n",
        "            del input_volume, mask_volume\n",
        "            gc.collect()\n",
        "            print(f\"total nums of patches is {len(input_patches)}\")\n",
        "\n",
        "        self.input_patches, self.mask_patches = input_patches, mask_patches\n",
        "\n",
        "    def get_random_patch_from_volume(self, input_volume, mask_volume):\n",
        "        patch_size = self.patch_size\n",
        "\n",
        "        d = np.random.randint(patch_size // 2, input_volume.shape[0] - patch_size // 2 - 1)\n",
        "        h = np.random.randint(patch_size // 2, input_volume.shape[1] - patch_size // 2 - 1)\n",
        "        w = np.random.randint(patch_size // 2, input_volume.shape[2] - patch_size // 2 - 1)\n",
        "\n",
        "        input_patch = input_volume[d - patch_size // 2:d + patch_size // 2,\n",
        "                                    h - patch_size // 2:h + patch_size // 2,\n",
        "                                    w - patch_size // 2:w + patch_size // 2]\n",
        "        mask_patch = mask_volume[d - patch_size // 2:d + patch_size // 2,\n",
        "                                  h - patch_size // 2:h + patch_size // 2,\n",
        "                                  w - patch_size // 2:w + patch_size // 2]\n",
        "\n",
        "        input_patch = input_patch[np.newaxis, ...]  # Shape: (1, depth, height, width)\n",
        "        mask_patch = mask_patch[np.newaxis, ...]  # Shape: (1, depth, height, width)\n",
        "\n",
        "        return input_patch, mask_patch\n"
      ],
      "metadata": {
        "id": "gZeb1H6zRXey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have a list of data folder paths in 'data_folders'\n",
        "drive_dir = '/content/drive/MyDrive/lung'\n",
        "patch_loader = PatchLoader(drive_dir)"
      ],
      "metadata": {
        "id": "6qlTs9doRZ36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_patches, mask_patches = patch_loader.get_patches()\n",
        "input_patches = torch.tensor(input_patches, dtype=torch.float32).to(device)\n",
        "mask_patches = torch.tensor(mask_patches, dtype=torch.float32).to(device)"
      ],
      "metadata": {
        "id": "zSi-Pqe6RcJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = UNet3D(in_channels=1)\n",
        "model2.load_state_dict(torch.load('/content/drive/MyDrive/NEW_MODEL2.pth'))\n",
        "model2.to(device)"
      ],
      "metadata": {
        "id": "7BCZRbRmRgHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "num_epochs = 1000\n",
        "batch_size = 10  # Adjust as needed\n",
        "optimizer = optim.Adam(model2.parameters(), lr=1e-3)\n",
        "scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "# criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([100.0])).to(device)\n",
        "criterion = dice_loss\n",
        "save_epochs = 5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model2.train()\n",
        "\n",
        "    # Create 2shuffled indices for this epoch\n",
        "    num_samples = len(input_patches)\n",
        "    indices = torch.randperm(num_samples)\n",
        "    if (epoch + 1) % save_epochs == 0:\n",
        "        model_save_path = '/content/drive/MyDrive/NEW_MODEL2.pth'  # Replace with your desired path and filename\n",
        "        torch.save(model2.state_dict(), model_save_path)\n",
        "        print(f\"Model saved at epoch {epoch}\\n\")\n",
        "\n",
        "    for batch_start in range(0, num_samples, batch_size):\n",
        "        # Get batch indices\n",
        "        batch_indices = indices[batch_start : batch_start + batch_size]\n",
        "\n",
        "        # Get input and mask batches\n",
        "        input_batch = input_patches[batch_indices].to(device) #Move to device here to reduce memory footprint\n",
        "        mask_batch = mask_patches[batch_indices].to(device)  #Move to device here to reduce memory footprint\n",
        "\n",
        "        # Training steps:\n",
        "        optimizer.zero_grad()\n",
        "        output = model2(input_batch)\n",
        "        loss = criterion(output, mask_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}], Batch [{batch_start // batch_size + 1}/{num_samples // batch_size}], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "id": "5xKChosFRjZz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "ULhLIHXQ9v0l",
        "MqPtSJC7VG5Q",
        "AMyoEI4VoCly",
        "87wV9cQIzIL6",
        "yIt-YLRRh-ne",
        "CcJGjzmHzNCj",
        "0fkfyPC7RFZO"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}