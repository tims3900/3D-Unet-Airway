{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULhLIHXQ9v0l"
      },
      "source": [
        "# IMPORTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HnEBshM95vIj"
      },
      "outputs": [],
      "source": [
        "!pip install pydicom\n",
        "!pip install nibabel\n",
        "\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import pydicom\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "\n",
        "from google.colab import drive, files\n",
        "from ipywidgets import interact, IntSlider\n",
        "from torch import nn, optim\n",
        "from torch.nn import BCELoss\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import gc\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfcOV0OQOs1E"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "drive_dir = '/content/drive/MyDrive/lung'\n",
        "data_folders = [os.path.join(drive_dir, f) for f in os.listdir(drive_dir) if os.path.isdir(os.path.join(drive_dir, f))]\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMyoEI4VoCly"
      },
      "source": [
        "# MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_Qfs87hehG6"
      },
      "outputs": [],
      "source": [
        "class DownCNNBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, use_padding=False):\n",
        "        super(DownCNNBlock, self).__init__()\n",
        "        padding = 1 if use_padding else 0\n",
        "\n",
        "        # Two 3x3x3 convolutional layers with ReLU activation\n",
        "        self.conv1 = nn.Conv3d(in_channels, out_channels, kernel_size=(3, 3, 3), padding=padding)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.conv2 = nn.Conv3d(out_channels, out_channels, kernel_size=(3, 3, 3), padding=padding)\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "        # 2x2x2 max pooling for downsampling\n",
        "        self.pooling = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=2)\n",
        "\n",
        "    def forward(self, input):\n",
        "        # print(\"DownCNNBLOCK\")\n",
        "        res = self.relu1(self.conv1(input))\n",
        "        res = self.relu2(self.conv2(res))\n",
        "        out = self.pooling(res)\n",
        "        return out, res\n",
        "\n",
        "class UpCNNBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, last_layer=False):\n",
        "        super(UpCNNBlock, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "\n",
        "        # 2x2x2 transposed convolution for upsampling\n",
        "        self.upconv = nn.ConvTranspose3d(in_channels - out_channels, in_channels - out_channels, kernel_size=(2, 2, 2), stride=2)\n",
        "        self.finalUpconv = nn.ConvTranspose3d(in_channels, in_channels, kernel_size=(2, 2, 2), stride=2)\n",
        "\n",
        "        # Two 3x3x3 convolutional layers with ReLU activation\n",
        "        self.conv1 = nn.Conv3d(in_channels + out_channels, out_channels, kernel_size=(3, 3, 3), padding=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.conv2 = nn.Conv3d(out_channels, out_channels, kernel_size=(3, 3, 3), padding=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.conv1Final = nn.Conv3d(in_channels + in_channels, out_channels, kernel_size=(3, 3, 3), padding=1)\n",
        "\n",
        "        # Flag to indicate if this is the last layer\n",
        "        self.last_layer = last_layer\n",
        "\n",
        "        # If it's the last layer, add a 1x1x1 convolution and sigmoid activation\n",
        "        self.conv3 = nn.Conv3d(out_channels, 1, kernel_size=(1, 1, 1))\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, input, residual=None):\n",
        "        # Apply transposed convolution for upsampling\n",
        "        if self.out_channels == 1:\n",
        "            out = self.finalUpconv(input)\n",
        "        else:\n",
        "            out = self.upconv(input)\n",
        "        if residual is not None:\n",
        "            if len(out.shape) == 4:\n",
        "                out = torch.cat((out, residual), dim=0)\n",
        "            else:\n",
        "              out = torch.cat((out, residual), dim=1)\n",
        "\n",
        "        # Apply convolutions and activations\n",
        "        if self.out_channels == 1:\n",
        "            out = self.conv1Final(out)\n",
        "        else:\n",
        "            out = self.relu1(self.conv1(out))\n",
        "\n",
        "        out = self.relu2(self.conv2(out))\n",
        "        # Apply final convolution and sigmoid if it's the last layer\n",
        "        if self.last_layer:\n",
        "            out = self.conv3(out)\n",
        "            out = self.sigmoid(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class UNet3D(nn.Module):\n",
        "    def __init__(self, in_channels, level_channels=[16, 32, 64, 128, 256]):\n",
        "        super(UNet3D, self).__init__()\n",
        "        self.a_block1 = DownCNNBlock(in_channels, level_channels[0], use_padding=True)\n",
        "        self.a_block2 = DownCNNBlock(level_channels[0], level_channels[1], use_padding=True)\n",
        "        self.a_block3 = DownCNNBlock(level_channels[1], level_channels[2], use_padding=True)\n",
        "        self.a_block4 = DownCNNBlock(level_channels[2], level_channels[3], use_padding=True)\n",
        "        self.a_block5 = DownCNNBlock(level_channels[3], level_channels[4], use_padding=True)\n",
        "\n",
        "        self.s_block5 = UpCNNBlock(level_channels[4] + level_channels[3], level_channels[3])\n",
        "        self.s_block4 = UpCNNBlock(level_channels[3] + level_channels[2], level_channels[2])\n",
        "        self.s_block3 = UpCNNBlock(level_channels[2] + level_channels[1], level_channels[1])\n",
        "        self.s_block2 = UpCNNBlock(level_channels[1] + level_channels[0], level_channels[0])\n",
        "        self.s_block1 = UpCNNBlock(level_channels[0], in_channels, last_layer=True)\n",
        "\n",
        "    def forward(self, input):\n",
        "        out1, res1 = self.a_block1(input)\n",
        "        out2, res2 = self.a_block2(out1)\n",
        "        out3, res3 = self.a_block3(out2)\n",
        "        out4, res4 = self.a_block4(out3)\n",
        "        out5, res5 = self.a_block5(out4)\n",
        "\n",
        "        out = self.s_block5(out5, res5)\n",
        "        out = self.s_block4(out, res4)\n",
        "        out = self.s_block3(out, res3)\n",
        "        out = self.s_block2(out, res2)\n",
        "        out = self.s_block1(out, res1)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWL1B8TD71uc"
      },
      "outputs": [],
      "source": [
        "def dice_loss(prediction, target, smooth=1e-5):\n",
        "    prediction = prediction.view(-1)\n",
        "    target = target.view(-1)\n",
        "\n",
        "    intersection = (prediction * target).sum()\n",
        "    union = prediction.sum() + target.sum()\n",
        "\n",
        "    dice = (2. * intersection + smooth) / (union + smooth)\n",
        "\n",
        "    return 1.0 - dice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVLXUV8yMAu1"
      },
      "source": [
        "# DATA PROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qijbfia2qgTB"
      },
      "outputs": [],
      "source": [
        "class DICOMCacheDataset():\n",
        "    def __init__(self, data_folders, cache_dir='numpy_dicom_images'):\n",
        "        self.data_folders = data_folders\n",
        "        self.cache_dir = cache_dir\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.scans)\n",
        "\n",
        "    def load_and_cache_volumes(self, input_dir, mask_path):\n",
        "        folder_name = os.path.basename(os.path.dirname(input_dir))\n",
        "        input_cache_path = os.path.join(self.cache_dir, folder_name + \"/input.pt\")\n",
        "        mask_cache_path = os.path.join(self.cache_dir, folder_name + \"/mask.pt\")\n",
        "\n",
        "        if os.path.exists(input_cache_path) and os.path.exists(mask_cache_path):\n",
        "            # print(f\"Loading volumes from cache for {input_dir}...\")\n",
        "            with open(input_cache_path, 'rb') as f:\n",
        "                input_volume = torch.load(f, map_location=torch.device('cpu'), weights_only=True)\n",
        "            with open(mask_cache_path, 'rb') as f:\n",
        "                mask_volume = torch.load(f, map_location=torch.device('cpu'), weights_only=True)\n",
        "        else:\n",
        "            # print(f\"Loading volumes from source and caching for {input_dir}...\")\n",
        "            dcm_files = [os.path.join(input_dir, f) for f in os.listdir(input_dir) if f.endswith('.dcm')]\n",
        "            dcm_files.sort(key=lambda f: pydicom.dcmread(f).SliceLocation)\n",
        "            input_volume = []\n",
        "\n",
        "            for file_path in tqdm(dcm_files, desc=\"Loading DICOM files\"):\n",
        "                ds = pydicom.dcmread(file_path)\n",
        "                input_volume.append(ds.pixel_array)\n",
        "            input_volume = np.stack(input_volume, axis=0)\n",
        "\n",
        "            mask_volume = nib.load(mask_path).get_fdata()\n",
        "            mask_volume = np.asarray(mask_volume)\n",
        "            mask_volume = np.rot90(mask_volume, k=1, axes=(0, 1))\n",
        "            mask_volume = np.flip(mask_volume, axis=0)\n",
        "            mask_volume = np.moveaxis(mask_volume, -1, 0)\n",
        "\n",
        "            os.makedirs(os.path.dirname(input_cache_path), exist_ok=True)\n",
        "            os.makedirs(os.path.dirname(mask_cache_path), exist_ok=True)\n",
        "\n",
        "            input_volume = torch.from_numpy(input_volume).float()\n",
        "            mask_volume = torch.from_numpy(mask_volume).float()\n",
        "\n",
        "            torch.save(input_volume, input_cache_path)\n",
        "            torch.save(mask_volume, mask_cache_path)\n",
        "        return input_volume, mask_volume\n",
        "\n",
        "    def get_volume(self, input_dir, mask_path):\n",
        "        folder_name = os.path.basename(os.path.dirname(input_dir))\n",
        "        input_cache_path = os.path.join(self.cache_dir, folder_name + \"/input.pt\")\n",
        "        mask_cache_path = os.path.join(self.cache_dir, folder_name + \"/mask.pt\")\n",
        "        if os.path.exists(input_cache_path) and os.path.exists(mask_cache_path):\n",
        "            with open(input_cache_path, 'rb') as f:\n",
        "                input_volume = torch.load(f, map_location=torch.device('cpu'), weights_only=True)\n",
        "            with open(mask_cache_path, 'rb') as f:\n",
        "                mask_volume = torch.load(f, map_location=torch.device('cpu'), weights_only=True)\n",
        "            return input_volume, mask_volume\n",
        "        else:\n",
        "            return self.load_and_cache_volumes(input_dir, mask_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSXe96wyMCdJ"
      },
      "outputs": [],
      "source": [
        "class GPUPatchLoader(Dataset):\n",
        "    def __init__(self, data_folders, patches_per_vol=5, patch_size=256, cache_dir='numpy_dicom_images'):\n",
        "        self.patches_per_vol = patches_per_vol\n",
        "        self.patch_size = patch_size\n",
        "        self.cache = DICOMCacheDataset(data_folders, cache_dir)\n",
        "        self.data = data_folders\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data) * self.patches_per_vol\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if idx == 101:\n",
        "            input_dir = '/content/drive/MyDrive/lung/1.3.6.1.4.1.14519.5.2.1.6279.6001.221945191226273284587353530424/Input'\n",
        "            mask_path = '/content/drive/MyDrive/lung/1.3.6.1.4.1.14519.5.2.1.6279.6001.221945191226273284587353530424/Mask/1.3.6.1.4.1.14519.5.2.1.6279.6001.221945191226273284587353530424.nii.gz'\n",
        "            example_volume, example_volume_mask = self.cache.load_and_cache_volumes(input_dir, mask_path)\n",
        "            example_patch, example_mask = self.get_patch(example_volume, example_volume_mask, (480,240,253))\n",
        "            return example_patch, example_mask\n",
        "        volume_idx = idx // self.patches_per_vol\n",
        "        input_dir = os.path.join(self.data[volume_idx], 'Input')\n",
        "        mask_path = os.path.join(self.data[volume_idx], 'Mask', os.listdir(os.path.join(self.data[volume_idx], 'Mask'))[0])\n",
        "\n",
        "        input_volume, mask_volume = self.cache.load_and_cache_volumes(input_dir, mask_path)\n",
        "        print(self.data[volume_idx])\n",
        "        print(input_volume.shape)\n",
        "        input_patch, mask_patch = self.get_patch(input_volume, mask_volume)\n",
        "        input_patch, mask_patch = self.augment_patch(input_patch, mask_patch)\n",
        "        return input_patch, mask_patch\n",
        "\n",
        "    def calculate_lung_bounding_box(mask_volume):\n",
        "        # Find non-zero indices in the mask\n",
        "        nonzero_indices = torch.nonzero(mask_volume)\n",
        "\n",
        "        # Get minimum and maximum indices along each dimension\n",
        "        min_d, min_h, min_w = nonzero_indices.min(dim=0).values\n",
        "        max_d, max_h, max_w = nonzero_indices.max(dim=0).values\n",
        "\n",
        "        # Add 30-voxel buffer\n",
        "        min_d = max(0, min_d - 30)\n",
        "        min_h = max(0, min_h - 30)\n",
        "        min_w = max(0, min_w - 30)\n",
        "        max_d = min(mask_volume.shape[0] - 1, max_d + 30)\n",
        "        max_h = min(mask_volume.shape[1] - 1, max_h + 30)\n",
        "        max_w = min(mask_volume.shape[2] - 1, max_w + 30)\n",
        "\n",
        "        return min_d, min_h, min_w, max_d, max_h, max_w\n",
        "\n",
        "    def get_patch(self, input_volume, mask_volume, coords=None):\n",
        "        patch_size = self.patch_size\n",
        "        mask_threshold = 500\n",
        "        if coords is None:\n",
        "            while True:\n",
        "                d = torch.randint(patch_size // 2, input_volume.shape[0] - patch_size // 2 - 1, (1,)).item()\n",
        "                h = torch.randint(patch_size // 2, input_volume.shape[1] - patch_size // 2 - 1, (1,)).item()\n",
        "                w = torch.randint(patch_size // 2, input_volume.shape[2] - patch_size // 2 - 1, (1,)).item()\n",
        "\n",
        "                input_patch = input_volume[d - patch_size // 2:d + patch_size // 2,\n",
        "                                            h - patch_size // 2:h + patch_size // 2,\n",
        "                                            w - patch_size // 2:w + patch_size // 2]\n",
        "                mask_patch = mask_volume[d - patch_size // 2:d + patch_size // 2,\n",
        "                                          h - patch_size // 2:h + patch_size // 2,\n",
        "                                          w - patch_size // 2:w + patch_size // 2]\n",
        "\n",
        "                if torch.sum(mask_patch) >= mask_threshold or torch.rand(1).item() >= 0.75:\n",
        "                    break\n",
        "        else:\n",
        "            d, h, w = coords\n",
        "            input_patch = input_volume[d - patch_size // 2:d + patch_size // 2,\n",
        "                                        h - patch_size // 2:h + patch_size // 2,\n",
        "                                        w - patch_size // 2:w + patch_size // 2]\n",
        "            mask_patch = mask_volume[d - patch_size // 2:d + patch_size // 2,\n",
        "                                      h - patch_size // 2:h + patch_size // 2,\n",
        "                                      w - patch_size // 2:w + patch_size // 2]\n",
        "\n",
        "        input_patch = input_patch.unsqueeze(0)\n",
        "        mask_patch = mask_patch.unsqueeze(0)\n",
        "        return input_patch, mask_patch\n",
        "\n",
        "    def augment_patch(self, input_patch, mask_patch):\n",
        "        flip, blackout, none = 0.05, 0.9, 0.05\n",
        "        choice = torch.rand(1).item()\n",
        "        if choice < flip:\n",
        "            axis = torch.randint(1, 4, [1,]).item()\n",
        "            input_patch = torch.flip(input_patch, dims=[axis])\n",
        "            mask_patch = torch.flip(mask_patch, dims=[axis])\n",
        "        elif choice < flip + blackout:\n",
        "            blackout_size = 32\n",
        "            mask_indices = torch.nonzero(mask_patch)\n",
        "            d_start = torch.randint(blackout_size // 2, input_patch.shape[1] - blackout_size, (1,)).item()\n",
        "            h_start = torch.randint(blackout_size // 2, input_patch.shape[2] - blackout_size, (1,)).item()\n",
        "            w_start = torch.randint(blackout_size // 2, input_patch.shape[3] - blackout_size, (1,)).item()\n",
        "\n",
        "            input_patch[:, d_start:d_start + blackout_size,\n",
        "                        h_start:h_start + blackout_size,\n",
        "                        w_start:w_start + blackout_size] = 0\n",
        "            mask_patch[:, d_start:d_start + blackout_size,\n",
        "                      h_start:h_start + blackout_size,\n",
        "                      w_start:w_start + blackout_size] = 0\n",
        "        return input_patch, mask_patch\n",
        "\n",
        "def visualize_patch(input_patch, mask_patch, slice_index=64):\n",
        "    plt.clf()\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(6, 5))\n",
        "\n",
        "    input_patch_np = input_patch[0][slice_index].cpu().numpy()\n",
        "    axes[0].imshow(input_patch_np, cmap='gray')\n",
        "    axes[0].set_title(f\"Input Patch Slice {slice_index}\")\n",
        "    del input_patch_np\n",
        "\n",
        "    mask_patch_np = mask_patch[0][slice_index].cpu().numpy()\n",
        "    axes[1].imshow(mask_patch_np, cmap='gray')\n",
        "    axes[1].set_title(f\"Mask Patch Slice {slice_index}\")\n",
        "    del mask_patch_np\n",
        "\n",
        "    plt.show()\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YvcRgL_FkJv"
      },
      "source": [
        "# TRAINING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPW_HYDQZTdn"
      },
      "outputs": [],
      "source": [
        "# patch_loader = GPUPatchLoader(data_folders[:10], patches_per_vol=5, patch_size=128)\n",
        "\n",
        "# batch_size = 4\n",
        "# for i in range(batch_size):\n",
        "#   input_patch, mask_patch = patch_loader[i]\n",
        "#   visualize_patch(input_patch, mask_patch)\n",
        "#   del input_patch\n",
        "#   del mask_patch\n",
        "# del patch_loader\n",
        "# gc.collect()\n",
        "print(data_folders)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3skk59vWUxN"
      },
      "outputs": [],
      "source": [
        "dummy_patch_loader = GPUPatchLoader(data_folders[:30], patches_per_vol=1, patch_size=256)\n",
        "for i in range(len(dummy_patch_loader)):\n",
        "    print(f\"loading in data[{i}]\")\n",
        "    input_patch, mask_patch = dummy_patch_loader[i]\n",
        "    del input_patch\n",
        "    del mask_patch\n",
        "del dummy_patch_loader\n",
        "gc.collect()\n",
        "# !zip -r /content/file.zip /content/numpy_dicom_images\n",
        "# files.download(\"/content/file.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kPfc8gvBajOl"
      },
      "outputs": [],
      "source": [
        "from types import NoneType\n",
        "model_GPU = UNet3D(in_channels=1).to(device)\n",
        "optimizer = optim.Adam(model_GPU.parameters(), lr=1e-4)\n",
        "criterion = dice_loss\n",
        "\n",
        "patch_loader = GPUPatchLoader(data_folders[:24], patches_per_vol=5, patch_size=256)\n",
        "\n",
        "num_epochs = 1000\n",
        "slice_index = 64\n",
        "\n",
        "loss_file_path = \"loss_values.txt\"\n",
        "checkpoint_dir = '/content/drive/MyDrive/MyCheckpoints'\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "example_patch = None\n",
        "\n",
        "train_losses = []\n",
        "dice_scores = []\n",
        "patch_losses = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model_GPU.train()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for i in tqdm(range(len(patch_loader)), desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n",
        "        input_patch, mask_patch = patch_loader[i]\n",
        "        input_patch = input_patch.unsqueeze(0).to(device)\n",
        "        mask_patch = mask_patch.unsqueeze(0).to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model_GPU(input_patch)\n",
        "        loss = criterion(output, mask_patch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    avg_epoch_loss = epoch_loss / len(patch_loader)\n",
        "    train_losses.append(epoch_loss / len(patch_loader))\n",
        "\n",
        "    model_GPU.eval()\n",
        "    with torch.no_grad():\n",
        "        if example_patch is None:\n",
        "            example_patch, example_mask = patch_loader[101]\n",
        "            example_patch = example_patch.unsqueeze(0).to(device)\n",
        "            example_mask = example_mask.unsqueeze(0).to(device)\n",
        "\n",
        "        output = model_GPU(example_patch)\n",
        "        patch_loss = criterion(output, example_mask).item()\n",
        "        patch_losses.append(patch_loss)\n",
        "\n",
        "    if (epoch) % 10 == 0:\n",
        "        with open(loss_file_path, 'a') as file:\n",
        "            file.write(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {avg_epoch_loss}\\n\")\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_epoch_loss}')\n",
        "\n",
        "    if (epoch) % 10 == 0:\n",
        "        o, m = output.detach().cpu().numpy(), example_mask.detach().cpu().numpy()\n",
        "        fig, axes = plt.subplots(2, 3, figsize=(18, 8), gridspec_kw={'width_ratios': [1, 1, 1.5], 'height_ratios': [1, 1]})  # Changed to 2 rows, 3 columns\n",
        "        axes[0, 0].imshow(o[0, 0, slice_index], cmap='jet')\n",
        "        axes[0, 0].set_title(f\"Output (Slice {slice_index})\")\n",
        "        axes[0, 0].axis('off')\n",
        "\n",
        "        axes[0, 1].imshow(m[0, 0, slice_index], cmap='jet')\n",
        "        axes[0, 1].set_title(f\"True Mask (Slice {slice_index})\")\n",
        "        axes[0, 1].axis('off')\n",
        "\n",
        "        axes[0, 2].plot(range(1, epoch + 2), patch_losses)\n",
        "        axes[0, 2].set_title(\"Patch Performance Over Time\")\n",
        "        axes[0, 2].set_xlabel(\"Epoch\")\n",
        "        axes[0, 2].set_ylabel(\"Dice Loss\")\n",
        "\n",
        "        gs = axes[1, 0].get_gridspec()\n",
        "        for ax in axes[1, :]:\n",
        "            ax.remove()\n",
        "\n",
        "        axbig = fig.add_subplot(gs[1, :])\n",
        "        axbig.plot(range(1, epoch + 2), train_losses)\n",
        "        axbig.set_title(\"Overall Model Performance Over Time\")\n",
        "        axbig.set_xlabel(\"Epoch\")\n",
        "        axbig.set_ylabel(\"Dice Loss\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        plt.close(fig)\n",
        "\n",
        "        checkpoint_path = os.path.join(checkpoint_dir, f'model_epoch_{epoch + 1}.pth')\n",
        "        torch.save({\n",
        "            'epoch': epoch + 1,\n",
        "            'model_state_dict': model_GPU.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "        }, checkpoint_path)\n",
        "        print(f'Checkpoint saved at epoch {epoch + 1} to {checkpoint_path}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DfFvIlXuGuil"
      },
      "outputs": [],
      "source": [
        "test_patch_loader = GPUPatchLoader(data_folders[30:35], patches_per_vol=5, patch_size=256)\n",
        "model_GPU.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    total_dice_loss = 0\n",
        "    for i in tqdm(range(len(test_patch_loader)), desc=\"Testing\"):\n",
        "        input_patch, mask_patch = test_patch_loader[i]\n",
        "        input_patch = input_patch.unsqueeze(0).to(device)\n",
        "        mask_patch = mask_patch.unsqueeze(0).to(device)\n",
        "\n",
        "        output = model_GPU(input_patch)\n",
        "        dice_loss_value = dice_loss(output, mask_patch).item()\n",
        "        total_dice_loss += dice_loss_value\n",
        "\n",
        "    average_dice_loss = total_dice_loss / len(test_patch_loader)\n",
        "    print(f\"Average Dice Loss on Test Set: {average_dice_loss}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "ULhLIHXQ9v0l"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}